## Grafana (deploy after datasources backends up)
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: grafana
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "2"
spec:
  project: default
  source:
    repoURL: https://grafana.github.io/helm-charts
    chart: grafana
    targetRevision: 8.5.11
    helm:
      values: |
        persistence:
          enabled: true
          size: 5Gi
          storageClassName: ceph-rbd # Adjust if different
        adminUser: admin
        adminPassword: admin123 # TODO: replace via Infisical secret ref / Secret valueFrom
        service:
          type: ClusterIP
        datasources:
          datasources.yaml:
            apiVersion: 1
            datasources:
              - name: Mimir
                type: prometheus
                access: proxy
                url: http://mimir-nginx.observability.svc.cluster.local
                isDefault: true
              - name: Loki
                type: loki
                access: proxy
                url: http://loki.observability.svc.cluster.local:3100
              - name: Tempo
                type: tempo
                access: proxy
                url: http://tempo.observability.svc.cluster.local:3100
                jsonData:
                  tracesToLogsV2:
                    datasourceUid: loki
                    filterByTraceID: true
        dashboardProviders:
          dashboardproviders.yaml:
            apiVersion: 1
            providers:
              - name: default
                orgId: 1
                folder: ''
                type: file
                disableDeletion: false
                editable: true
                options:
                  path: /var/lib/grafana/dashboards/default
        dashboards: {}
  destination:
    server: https://kubernetes.default.svc
    namespace: observability
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
---
# Mimir (monolithic mode to start)
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: mimir
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  project: default
  source:
    repoURL: https://grafana.github.io/helm-charts
    chart: mimir-distributed
    targetRevision: 5.2.0 # pin suitable version
    helm:
      values: |
        global:
          extraEnv:
            - name: JAEGER_AGENT_HOST
              value: "tempo.observability.svc.cluster.local"
        runtimeConfig: {}
        mimir:
          structuredConfig:
            common:
              storage:
                backend: filesystem
                filesystem:
                  # Use a sibling directory to the ingester TSDB path (/data/tsdb) to avoid overlap constraint
                  dir: /data/blocks
            # Lean: omit limits (use defaults); add later if needed.
        ingester:
          replicas: 1
          persistentVolume:
            enabled: true
            size: 10Gi
            storageClass: ceph-rbd
          zoneAwareReplication:
            enabled: false
        compactor:
          enabled: false
        store_gateway:
          enabled: false
        overrides_exporter:
          enabled: false
        alertmanager:
          enabled: false
        ruler:
          enabled: false
        minio:
          enabled: false
        metaMonitoring:
          dashboards:
            enabled: true
            label: grafana_dashboard
            labelValue: "1"
  destination:
    server: https://kubernetes.default.svc
    namespace: observability
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
---
# Loki
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: loki
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  project: default
  source:
    repoURL: https://grafana.github.io/helm-charts
    chart: loki
    targetRevision: 5.41.4
    helm:
      values: |
        deploymentMode: SingleBinary
        loki:
          commonConfig:
            replication_factor: 1
          storage:
            type: filesystem
          auth_enabled: false
        singleBinary:
          replicas: 1
          persistence:
            enabled: true
            size: 10Gi
            storageClass: ceph-rbd
        gateway:
          enabled: false
        read:
          replicas: 0
        write:
          replicas: 0
        # Disable extras we don't need for lean setup
          lokiCanary:
            enabled: false
          grafana-agent-operator:
            enabled: false
          grafanaAgentOperator:
            enabled: false
          agent:
            enabled: false
          agentOperator:
            enabled: false
          grafana:
            agent:
              enabled: false
            agentOperator:
              enabled: false
  destination:
    server: https://kubernetes.default.svc
    namespace: observability
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
---
# Tempo
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: tempo
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  project: default
  source:
    repoURL: https://grafana.github.io/helm-charts
    chart: tempo
    targetRevision: 1.16.0
    helm:
      values: |
        tempo:
          storage:
            trace:
              backend: local
              local:
                path: /var/tempo/traces
          metricsGenerator:
            enabled: false
          otlp:
            grpc:
              enabled: true
            http:
              enabled: true
        persistence:
          enabled: true
          size: 10Gi
          storageClassName: ceph-rbd
        ingress:
          enabled: false
  destination:
    server: https://kubernetes.default.svc
    namespace: observability
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
---
# Promtail
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: promtail
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "1"
spec:
  project: default
  source:
    repoURL: https://grafana.github.io/helm-charts
    chart: promtail
    targetRevision: 6.15.5
    helm:
      values: |
        config:
          clients:
            - url: http://loki.observability.svc.cluster.local:3100/loki/api/v1/push
          snippets:
            pipelineStages:
              - cri: {}
        extraScrapeConfigs: []
  destination:
    server: https://kubernetes.default.svc
    namespace: observability
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
---
# Grafana Alloy (agent)
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: alloy
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "1"
spec:
  project: default
  source:
    repoURL: https://grafana.github.io/helm-charts
    chart: alloy
    targetRevision: 0.5.0
    helm:
      values: |
        alloy:
          configMap:
            create: true
            content: |
              // Logs collection and forwarding
              loki.source.kubernetes "pods" {
                targets    = discovery.kubernetes.pods.targets
                forward_to = [loki.process.pods.receiver]
              }

              loki.process "pods" {
                forward_to = [loki.write.default.receiver]

                stage.cri {}
                stage.labels {
                  values = {
                    cluster = "home-cluster",
                  }
                }
              }

              loki.write "default" {
                endpoint {
                  url = "http://loki.observability.svc.cluster.local:3100/loki/api/v1/push"
                }
              }

              // Metrics collection and forwarding
              discovery.kubernetes "endpoints" {
                role = "endpoints"
              }

              prometheus.scrape "kube_state_metrics" {
                targets = [
                  {
                    "__address__" = "kube-state-metrics.observability.svc.cluster.local:8080",
                    "job" = "kube-state-metrics",
                  },
                ]
                forward_to     = [prometheus.remote_write.default.receiver]
                scrape_interval = "30s"
              }

              prometheus.scrape "node_exporter" {
                targets = discovery.kubernetes.pods.targets
                forward_to     = [prometheus.remote_write.default.receiver]
                scrape_interval = "30s"
                relabel {
                  source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
                  regex        = "prometheus-node-exporter"
                  action       = "keep"
                }
                relabel {
                  source_labels = ["__meta_kubernetes_pod_ip"]
                  target_label  = "__address__"
                  replacement   = "${1}:9100"
                }
              }

              prometheus.scrape "kubernetes_pods" {
                targets    = discovery.kubernetes.pods.targets
                forward_to = [prometheus.remote_write.default.receiver]
                scrape_interval = "30s"
                relabel {
                  source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_scrape"]
                  regex        = "true"
                  action       = "keep"
                }
                relabel {
                  source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_path"]
                  regex        = "(.+)"
                  target_label  = "__metrics_path__"
                  replacement   = "${1}"
                }
                relabel {
                  source_labels = ["__address__", "__meta_kubernetes_pod_annotation_prometheus_io_port"]
                  regex        = "([^:]+)(?::[0-9]+)?;([0-9]+)"
                  replacement   = "$1:$2"
                  target_label  = "__address__"
                }
              }

              prometheus.remote_write "default" {
                endpoint {
                  url = "http://mimir-nginx.observability.svc.cluster.local/api/v1/push"
                }
              }

              // Traces collection and forwarding
              otelcol.receiver.otlp "default" {
                grpc {
                  endpoint = "0.0.0.0:4317"
                }
                http {
                  endpoint = "0.0.0.0:4318"
                }
                output {
                  traces  = [otelcol.exporter.otlp.tempo.input]
                  metrics = [otelcol.exporter.otlp.tempo.input]
                  logs    = [otelcol.exporter.otlp.tempo.input]
                }
              }

              otelcol.exporter.otlp "tempo" {
                client {
                  endpoint = "tempo.observability.svc.cluster.local:4317"
                  insecure = true
                }
              }

              // Kubernetes discovery
              discovery.kubernetes "pods" {
                role = "pod"
              }
        controller:
          type: daemonset
        service:
          enabled: false
        rbac:
          create: true
          rules:
            - apiGroups: [""]
              resources: ["nodes", "nodes/proxy", "services", "endpoints", "pods"]
              verbs: ["get", "list", "watch"]
            - apiGroups: ["discovery.k8s.io"]
              resources: ["endpointslices"]
              verbs: ["get", "list", "watch"]
        serviceAccount:
          create: true
  destination:
    server: https://kubernetes.default.svc
    namespace: observability
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
---
# kube-state-metrics
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-state-metrics
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "1"
spec:
  project: default
  source:
    repoURL: https://prometheus-community.github.io/helm-charts
    chart: kube-state-metrics
    targetRevision: 5.23.0
    helm:
      values: |
        prometheus:
          monitor:
            enabled: false
  destination:
    server: https://kubernetes.default.svc
    namespace: observability
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
---
# node-exporter
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: node-exporter
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "1"
spec:
  project: default
  source:
    repoURL: https://prometheus-community.github.io/helm-charts
    chart: prometheus-node-exporter
    targetRevision: 4.38.0
    helm:
      values: |
        service:
          port: 9100
        prometheus:
          monitor:
            enabled: false
  destination:
    server: https://kubernetes.default.svc
    namespace: observability
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
