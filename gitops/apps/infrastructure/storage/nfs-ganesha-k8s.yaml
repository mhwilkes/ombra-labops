# NFS-Ganesha deployment for Kubernetes cluster
# This provides NFS export of CephFS that can be used by media applications
# Leverages existing Ceph CSI connectivity in the cluster

# Dedicated namespace for NFS-Ganesha
---
apiVersion: v1
kind: Namespace
metadata:
  name: nfs-ganesha  
  labels:
    name: nfs-ganesha
    component: storage-infrastructure
    "pod-security.kubernetes.io/enforce": "privileged"
    "pod-security.kubernetes.io/audit": "privileged"
    "pod-security.kubernetes.io/warn": "privileged"

# ServiceAccount for NFS-Ganesha
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-ganesha
  namespace: nfs-ganesha

# ClusterRole for NFS-Ganesha (needs access to nodes for NFS exports)
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nfs-ganesha
rules:
- apiGroups: [""]
  resources: ["persistentvolumes", "persistentvolumeclaims", "nodes"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["endpoints", "services"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nfs-ganesha
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nfs-ganesha
subjects:
- kind: ServiceAccount
  name: nfs-ganesha
  namespace: nfs-ganesha

# CephFS PVC for NFS-Ganesha to export
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cephfs-media-export
  namespace: nfs-ganesha
  labels:
    app: nfs-ganesha
    component: storage
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: ceph-cephfs
  resources:
    requests:
      storage: 2Ti

# ConfigMap for NFS-Ganesha configuration
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nfs-ganesha-config
  namespace: nfs-ganesha
  labels:
    app: nfs-ganesha
data:  
  ganesha.conf: |
    # NFS-Ganesha configuration for CephFS export using CephFS FSAL
    EXPORT {
        Export_Id = 1;
        Path = "/";
        Pseudo = "/media";
        Protocols = 4;
        Transports = TCP;
        Access_Type = RW;
        Squash = No_Root_Squash;
        
        # Security - allow access from cluster network
        Sectype = sys;
        
        # CephFS FSAL for direct CephFS access
        FSAL {
            Name = CEPH;
            User_Id = "admin";
            Secret_Access_Key = "/etc/ceph/keyring";
            # Ceph configuration file path
            Ceph_Conf = "/etc/ceph/ceph.conf";
        }
        
        # Allow access from Kubernetes pod network
        CLIENT {
            Clients = 10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16;
            Access_Type = RW;
            Squash = No_Root_Squash;
        }
    }
    
    # NFS Core parameters
    NFS_Core_Param {
        NFS_Port = 2049;
        MNT_Port = 20048;
        NFS_Protocols = 4;
        Nb_Worker = 16;
    }      # Enable NFS v4
    NFSv4 {
        Minor_Versions = 1, 2;
        Delegations = true;
        RecoveryBackend = fs;
        RecoveryRoot = "/var/lib/nfs/ganesha";
    }
    
    # Logging
    LOG {
        Default_Log_Level = INFO;
        Components {
            FSAL = INFO;
            NFS4 = INFO;
            EXPORT = INFO;
        }
    }

# NFS-Ganesha Deployment
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-ganesha
  namespace: nfs-ganesha
  labels:
    app: nfs-ganesha
    component: nfs-server
spec:
  replicas: 2  # For high availability
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      app: nfs-ganesha
  template:
    metadata:
      labels:
        app: nfs-ganesha
        component: nfs-server    
    spec:
      serviceAccountName: nfs-ganesha
      # Ensure pods run on different nodes
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: nfs-ganesha
              topologyKey: kubernetes.io/hostname
      # Security context for NFS-Ganesha - requires privileged access      
      securityContext:
        runAsUser: 0
        runAsGroup: 0
        fsGroup: 0      
      containers:
      - name: nfs-ganesha
        image: quay.io/ceph/ceph:v18.2.0
        imagePullPolicy: IfNotPresent
        command:
        - /bin/bash
        - -c
        - |
          set -e
          echo "Preparing Ceph configuration..."
          
          # Create ceph.conf
          cat > /etc/ceph/ceph.conf << EOF
          [global]
          fsid = $(cat /etc/ceph/fsid)
          mon_host = $(cat /etc/ceph/mon_host)
          auth_cluster_required = cephx
          auth_service_required = cephx
          auth_client_required = cephx
          EOF
          
          # Create admin keyring for CephFS FSAL
          cat > /etc/ceph/keyring << EOF
          [client.admin]
          key = $(cat /etc/ceph/admin_key)
          caps mds = "allow *"
          caps mon = "allow *"
          caps osd = "allow *"
          caps mgr = "allow *"
          EOF
          
          echo "Starting NFS-Ganesha with CephFS FSAL..."
          exec /usr/bin/ganesha.nfsd -F -f /etc/ganesha/ganesha.conf -N NIV_EVENT
        ports:
        - name: nfs
          containerPort: 2049
          protocol: TCP
        - name: mountd
          containerPort: 20048
          protocol: TCP
        - name: rpcbind
          containerPort: 111
          protocol: TCP
        - name: rpcbind-udp
          containerPort: 111
          protocol: UDP
        volumeMounts:
        - name: ganesha-config
          mountPath: /etc/ganesha
          readOnly: true
        - name: ceph-secrets
          mountPath: /etc/ceph
          readOnly: true
        - name: recovery-backend
          mountPath: /var/lib/nfs/ganesha
        - name: run
          mountPath: /run
        - name: var-lib-nfs
          mountPath: /var/lib/nfs
        securityContext:
          privileged: true
          runAsUser: 0
          capabilities:
            add:
            - SYS_ADMIN
            - DAC_READ_SEARCH
            - DAC_OVERRIDE
        resources:
          requests:
            cpu: 100m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 1Gi
        livenessProbe:
          tcpSocket:
            port: 2049
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 2049
          initialDelaySeconds: 10
          periodSeconds: 5      
      volumes:
      - name: ganesha-config
        configMap:
          name: nfs-ganesha-config
      - name: ceph-secrets
        secret:
          secretName: ceph-secret
      - name: recovery-backend
        emptyDir: {}
      - name: run
        emptyDir: {}
      - name: var-lib-nfs
        emptyDir: {}

# LoadBalancer Service for NFS-Ganesha
---
apiVersion: v1
kind: Service
metadata:
  name: nfs-ganesha-lb
  namespace: nfs-ganesha
  labels:
    app: nfs-ganesha
    component: load-balancer
spec:
  type: LoadBalancer
  loadBalancerIP: 192.168.55.220  # Reserve an IP for NFS service
  ports:
  - name: nfs
    port: 2049
    targetPort: 2049
    protocol: TCP
  - name: mountd
    port: 20048
    targetPort: 20048
    protocol: TCP
  - name: rpcbind-tcp
    port: 111
    targetPort: 111
    protocol: TCP
  - name: rpcbind-udp
    port: 111
    targetPort: 111
    protocol: UDP
  selector:
    app: nfs-ganesha

# Internal ClusterIP Service for cluster access
---
apiVersion: v1
kind: Service
metadata:
  name: nfs-ganesha
  namespace: nfs-ganesha
  labels:
    app: nfs-ganesha
    component: cluster-service
spec:
  type: ClusterIP
  ports:
  - name: nfs
    port: 2049
    targetPort: 2049
    protocol: TCP
  - name: mountd
    port: 20048
    targetPort: 20048
    protocol: TCP
  - name: rpcbind-tcp
    port: 111
    targetPort: 111
    protocol: TCP
  selector:
    app: nfs-ganesha

# Directory structure initialization job
---
apiVersion: batch/v1
kind: Job
metadata:
  name: nfs-media-structure-init
  namespace: nfs-ganesha
  labels:
    app: nfs-ganesha
    component: init
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
spec:
  ttlSecondsAfterFinished: 300
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: structure-init
        image: busybox:1.36
        securityContext:
          runAsUser: 0
          runAsGroup: 0
        command:
        - /bin/sh
        - -c
        - |
          echo "Creating TRASHGuides directory structure for NFS export..."
          
          # Create the recommended folder structure
          mkdir -p /export/media/torrents/{movies,tv,music,books}
          mkdir -p /export/media/usenet/incomplete
          mkdir -p /export/media/usenet/complete/{movies,tv,music,books}
          mkdir -p /export/media/media/{movies,tv,music,books}
          mkdir -p /export/media/downloads
          
          echo "Setting proper permissions..."
          find /export/media -type d -exec chmod 775 {} \; 2>/dev/null || true
          find /export/media -type d -exec chown 2000:2000 {} \; 2>/dev/null || true
          
          echo "NFS export directory structure created successfully!"
          echo "Final structure:"
          find /export/media -type d 2>/dev/null | sort || echo "Structure created"
          
          # Create a test file to verify NFS functionality
          echo "NFS-Ganesha ready - $(date)" > /export/media/nfs-ready.txt
          chmod 664 /export/media/nfs-ready.txt
          chown 2000:2000 /export/media/nfs-ready.txt
        volumeMounts:
        - name: cephfs-export
          mountPath: /export/media
      volumes:
      - name: cephfs-export
        persistentVolumeClaim:
          claimName: cephfs-media-export
