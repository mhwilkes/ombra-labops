apiVersion: batch/v1
kind: Job
metadata:
  name: generate-argocd-kubeconfig
  namespace: secrets
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
    argocd.argoproj.io/sync-wave: "1"
spec:
  backoffLimit: 3
  template:
    spec:
      serviceAccountName: kubeconfig-generator
      restartPolicy: OnFailure
      containers:
        - name: generator
          image: bitnami/kubectl:latest
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
            - -c
            - |
              set -euo pipefail
              echo "Starting kubeconfig generation from in-cluster credentials..."
              
              # Get namespace and service account name
              NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)
              SERVICE_ACCOUNT="kubeconfig-generator"
              POD_NAME=$(hostname 2>/dev/null || echo "")
              
              # Try to get service account from pod if available
              if [ -n "$POD_NAME" ]; then
                SA_FROM_POD=$(kubectl get pod "$POD_NAME" -n "$NAMESPACE" -o jsonpath='{.spec.serviceAccountName}' 2>/dev/null || echo "")
                [ -n "$SA_FROM_POD" ] && SERVICE_ACCOUNT="$SA_FROM_POD"
              fi
              
              echo "Using service account: $SERVICE_ACCOUNT in namespace: $NAMESPACE"
              
              # Create a TokenRequest with longer expiration (1 year = 8760 hours)
              # This gives us a much longer-lived token than the default 1-hour projected token
              # NOTE: We do NOT bind the token to the pod, so it remains valid after the job pod is deleted
              echo "Creating long-lived token for service account (unbound, so it persists after pod deletion)..."
              TOKEN_RESPONSE=$(kubectl create token "$SERVICE_ACCOUNT" -n "$NAMESPACE" \
                --duration=8760h \
                2>/dev/null || echo "")
              
              if [ -n "$TOKEN_RESPONSE" ]; then
                TOKEN="$TOKEN_RESPONSE"
                echo "✓ Created long-lived token (1 year expiration)"
              else
                # Fallback to projected token if TokenRequest fails (older Kubernetes versions)
                echo "⚠️  TokenRequest failed, falling back to projected token (1 hour expiration)"
                TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
              fi
              
              CA_CERT="/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
              
              # Try to get external API server address from cluster config
              # First try to get from ProxmoxCluster (if it exists)
              EXTERNAL_HOST=$(kubectl get proxmoxcluster proxmox-cluster -n default -o jsonpath='{.spec.controlPlaneEndpoint.host}' 2>/dev/null || echo "")
              EXTERNAL_PORT=$(kubectl get proxmoxcluster proxmox-cluster -n default -o jsonpath='{.spec.controlPlaneEndpoint.port}' 2>/dev/null || echo "")
              
              # If that doesn't work, try to get from kubernetes service endpoints (control plane nodes)
              if [ -z "$EXTERNAL_HOST" ]; then
                # Try to find a control plane node address
                EXTERNAL_HOST=$(kubectl get nodes -l node-role.kubernetes.io/control-plane -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}' 2>/dev/null || echo "")
                [ -z "$EXTERNAL_PORT" ] && EXTERNAL_PORT="6443"
              fi
              
              # If still no external endpoint, use internal service IP as fallback
              if [ -z "$EXTERNAL_HOST" ]; then
                # Fall back to internal service IP (only works from within cluster)
                API_SERVER="https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_SERVICE_PORT}"
                echo "⚠️  Warning: Could not find external API server, using internal: $API_SERVER"
                echo "⚠️  This kubeconfig will only work from within the cluster or via kubectl port-forward"
              else
                # Use external endpoint
                [ -z "$EXTERNAL_PORT" ] && EXTERNAL_PORT="6443"
                API_SERVER="https://${EXTERNAL_HOST}:${EXTERNAL_PORT}"
                echo "✓ Found external API server: $API_SERVER"
              fi
              
              echo "API Server: $API_SERVER"
              echo "Token found: $(echo "$TOKEN" | cut -c1-20)..."
              
              # Base64 encode CA cert (portable across base64 implementations)
              CA_B64=$(base64 < "$CA_CERT" | tr -d '\n')
              
              # Create kubeconfig file using printf to avoid heredoc YAML parsing issues
              printf 'apiVersion: v1\nkind: Config\nclusters:\n- name: default-cluster\n  cluster:\n    server: %s\n    certificate-authority-data: %s\ncontexts:\n- name: default-context\n  context:\n    cluster: default-cluster\n    namespace: %s\n    user: %s\ncurrent-context: default-context\nusers:\n- name: %s\n  user:\n    token: %s\n' "$API_SERVER" "$CA_B64" "$NAMESPACE" "$SERVICE_ACCOUNT" "$SERVICE_ACCOUNT" "$TOKEN" > /tmp/kubeconfig
              
              echo "Generated kubeconfig file"
              
              # Verify kubeconfig is valid
              if kubectl --kubeconfig=/tmp/kubeconfig cluster-info >/dev/null 2>&1; then
                echo "✅ Kubeconfig validation successful"
              else
                echo "⚠️  Kubeconfig validation failed, but continuing..."
                kubectl --kubeconfig=/tmp/kubeconfig cluster-info || true
              fi
              
              # Base64 encode the kubeconfig for ConfigMap (portable)
              KUBE_B64=$(base64 < /tmp/kubeconfig | tr -d '\n')
              
              # Update secret in 'secrets' namespace (managed by ArgoCD from Git)
              echo "Updating secret cluster-kubeconfig in secrets namespace..."
              # Use patch to update data without deleting (preserves ArgoCD management)
              KUBE_B64_DATA=$(base64 < /tmp/kubeconfig | tr -d '\n')
              kubectl -n secrets patch secret cluster-kubeconfig \
                -p "{\"data\":{\"kubeconfig\":\"$KUBE_B64_DATA\"}}" \
                --type=merge 2>/dev/null || \
              kubectl -n secrets create secret generic cluster-kubeconfig \
                --from-file=kubeconfig=/tmp/kubeconfig \
                --dry-run=client -o yaml | \
              kubectl label --local -f - \
                app.kubernetes.io/name=cluster-kubeconfig \
                app.kubernetes.io/managed-by=argocd \
                purpose=cluster-access \
                -o yaml | \
              kubectl -n secrets apply -f -
              echo "✅ Secret cluster-kubeconfig updated in secrets namespace"
              
              # Update ConfigMap in 'secrets' namespace (managed by ArgoCD from Git)
              echo "Updating configmap cluster-kubeconfig-view in secrets namespace..."
              # Check if configmap exists
              if kubectl -n secrets get configmap cluster-kubeconfig-view >/dev/null 2>&1; then
                echo "ConfigMap exists, patching it..."
                # Escape special characters in the base64 string for JSON
                ESCAPED_KUBE_B64=$(echo "$KUBE_B64" | sed 's/"/\\"/g')
                ESCAPED_API_SERVER=$(echo "$API_SERVER" | sed 's/"/\\"/g')
                ESCAPED_SA=$(echo "$SERVICE_ACCOUNT" | sed 's/"/\\"/g')
                ESCAPED_NS=$(echo "$NAMESPACE" | sed 's/"/\\"/g')
                # Patch the configmap data
                kubectl -n secrets patch configmap cluster-kubeconfig-view \
                  --type merge \
                  -p "{\"data\":{\"kubeconfig.b64\":\"$ESCAPED_KUBE_B64\",\"api-server\":\"$ESCAPED_API_SERVER\",\"service-account\":\"$ESCAPED_SA\",\"namespace\":\"$ESCAPED_NS\"}}"
                if [ $? -eq 0 ]; then
                  echo "✅ ConfigMap cluster-kubeconfig-view patched successfully"
                else
                  echo "⚠️  Patch failed, trying alternative method..."
                  # Alternative: use kubectl set data
                  kubectl -n secrets create configmap cluster-kubeconfig-view \
                    --from-literal=kubeconfig.b64="$KUBE_B64" \
                    --from-literal=api-server="$API_SERVER" \
                    --from-literal=service-account="${SERVICE_ACCOUNT}" \
                    --from-literal=namespace="${NAMESPACE}" \
                    --dry-run=client -o yaml | \
                  kubectl -n secrets replace -f -
                fi
              else
                echo "ConfigMap doesn't exist, creating it..."
                kubectl -n secrets create configmap cluster-kubeconfig-view \
                  --from-literal=kubeconfig.b64="$KUBE_B64" \
                  --from-literal=instructions="Decode kubeconfig.b64 with: echo '<base64>' | base64 -d > kubeconfig" \
                  --from-literal=api-server="$API_SERVER" \
                  --from-literal=service-account="${SERVICE_ACCOUNT}" \
                  --from-literal=namespace="${NAMESPACE}"
                kubectl -n secrets label configmap cluster-kubeconfig-view \
                  app.kubernetes.io/name=cluster-kubeconfig \
                  app.kubernetes.io/managed-by=argocd \
                  purpose=cluster-access \
                  --overwrite
              fi
              echo "✅ ConfigMap cluster-kubeconfig-view updated in secrets namespace"
              echo ""
              echo ""
              echo "Access your kubeconfig via ArgoCD UI:"
              echo "  1. Go to Applications > secrets-stack > Resources"
              echo "  2. Filter by label: purpose=cluster-access"
              echo "  3. View secret 'cluster-kubeconfig' or configmap 'cluster-kubeconfig-view' in secrets namespace"
      securityContext:
        runAsUser: 0
        runAsGroup: 0
